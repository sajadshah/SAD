# Project Title

A speech activity detection using GMM and deep neural network. 

We studied methods for modeling speech/non-speech regions in audio signals known as Speech Activity Detection. The question to be answered in this problem is which class the audio frame is classified to? speech or non-speech? First I've prepared a 40 hours data from audio signal of movies labeled according to their synchronized subtitles. Given a labeled data set, for each audio frame MFCC and PLP features has been extracted. As model for binary classifier first we trained two separated GMM each for speech and non-speech classes. For considering context information, feature vector of surrounding frames has been concatenated to each frame feature vector and then HLDA has been applied as dimensionality reduction method. As second method, deep neural networks were used to model posterior probability of assigning each frame to speech and non-speech classes. Multi-layer perceptron and recurrent models has been trained with different configurations. Context information (feature of surrounding frames) has been feed to the network directly. Deep neural models with many (about 40) frames as context had better results than GMM. According to results, context information is very useful in solving SAD problem and can lead to improve the performance.
